apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namePrefix: flan-t5-3b-

commonLabels:
  app: text-gen-flan-t5-xl

resources:
  - ../../base

patchesStrategicMerge:
  - ../../base/patches/gpus/1-gpu.yaml
  # To load the trained prompts
  - ../../base/patches/pvcs/prompts-pvc.yaml
  # These limits are for the larger t5 model
  #TODO adjust them for the smaller models
  - ../../base/patches/limits/t5-xxl.yaml
  - |-
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: inference-server
   spec:
     template:
       spec:
         containers:
           - name: server
             env:
             - name: MODEL_NAME
               value: google/flan-t5-xl
             # dtype set to bfloat16 to match tuned prompts
             - name: DTYPE_STR
               value: bfloat16

             #TODO This value is for the larger t5 model, can be increased
             - name: MAX_BATCH_WEIGHT
               value: "47458400"