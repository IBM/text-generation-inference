apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-server
spec:
  template:
    spec:
      containers:
        - name: server
          env:
            - name: MAX_SEQUENCE_LENGTH
              value: "2048"
            - name: MAX_NEW_TOKENS
              value: "1024"
            - name: MAX_BATCH_SIZE
              value: "32"
            - name: MAX_CONCURRENT_REQUESTS
              value: "64"
